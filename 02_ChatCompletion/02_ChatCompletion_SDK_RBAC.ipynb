{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 SDK | 01 Chat Completion\n",
    "\n",
    "## Azure Environment\n",
    "\n",
    "To execute the sample code Azure service specific information like endpoint, api key etc. is needed ([Details and instructions can be found here](../01_DemoEnvironment/01_Environment.ipynb))\n",
    "\n",
    "## Step 1: Create OpenAIClient\n",
    "\n",
    "The OpenAIClient from Azure.AI.OpenAI is a .NET client library that acts as the centralized point for all .NET functionality that want to interact with a deployed Azure OpenAI Large Language Model. It provides methods to access the OpenAI REST APIs for various tasks such as text completion, text embedding, and chat completion, etc.. It also allows developers to specify the model, engine, and options for each request, such as temperature, frequency penalty, presence penalty, and stop sequences. \n",
    "\n",
    "The OpenAIClient can connect to any Azure OpenAI resource or to the non-Azure OpenAI inference endpoint, making it a versatile and powerful tool for .NET development with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.OpenAI, 1.0.0-beta.12</span></li><li><span>Azure.Identity, 1.4.0</span></li><li><span>DotNetEnv, 2.5.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Client created...\r\n"
     ]
    }
   ],
   "source": [
    "#r \"nuget: Azure.AI.OpenAI, 1.0.0-beta.12\"\n",
    "#r \"nuget: DotNetEnv, 2.5.0\"\n",
    "#r \"nuget: Azure.Identity, 1.4.0\"\n",
    "\n",
    "using Azure; \n",
    "using Azure.Core;\n",
    "using Azure.Identity;\n",
    "using Azure.AI.OpenAI;\n",
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "using System.Text.Json; \n",
    "\n",
    "//configuration file is created during environment creation\n",
    "static string _configurationFile = @\"../Configuration/application.env\";\n",
    "Env.Load(_configurationFile);\n",
    "\n",
    "\n",
    "string assetsFolder = Path.Combine(Directory.GetCurrentDirectory(), \"..\", \"..\", \"assets\");\n",
    "string oAiApiKey = Environment.GetEnvironmentVariable(\"WS_AOAI_APIKEY\") ?? \"WS_AOAI_APIKEY not found\";\n",
    "string oAiEndpoint = Environment.GetEnvironmentVariable(\"WS_AOAI_ENDPOINT\") ?? \"WS_AOAI_ENDPOINT not found\";\n",
    "string chatCompletionDeploymentName = Environment.GetEnvironmentVariable(\"WS_CHATCOMPLETION_DEPLOYMENTNAME\") ?? \"WS_CHATCOMPLETION_DEPLOYMENTNAME not found\";\n",
    "\n",
    "AzureKeyCredential azureKeyCredential = new AzureKeyCredential(oAiApiKey);\n",
    "OpenAIClient openAIClient = new OpenAIClient(new Uri(oAiEndpoint), azureKeyCredential);\n",
    "\n",
    "Environment.SetEnvironmentVariable(\"AZURE_CLIENT_ID\", \"7ddb7f49-3178-42a1-8875-b19c382e6233\");\n",
    "Environment.SetEnvironmentVariable(\"AZURE_CLIENT_SECRET\", \"ZYu8Q~bfRPCc1JEUTUuE9IO0M9LGAQtv56O2xaGg\");\n",
    "Environment.SetEnvironmentVariable(\"AZURE_TENANT_ID\", \"72f988bf-86f1-41af-91ab-2d7cd011db47\");\n",
    "\n",
    "//RBAC Loging\n",
    "var credOpts = new DefaultAzureCredentialOptions()\n",
    "{\n",
    "    ExcludeAzureCliCredential = true,\n",
    "    ExcludeAzurePowerShellCredential = true,\n",
    "    //ExcludeEnvironmentCredential = true,\n",
    "    ExcludeInteractiveBrowserCredential = true,\n",
    "    ExcludeManagedIdentityCredential = true,\n",
    "    ExcludeVisualStudioCredential = true,\n",
    "    ExcludeSharedTokenCacheCredential = true,\n",
    "    ExcludeVisualStudioCodeCredential = true,\n",
    "};\n",
    "var credential = new DefaultAzureCredential(credOpts);\n",
    "VisualStudioCodeCredential credentialVSCode = new VisualStudioCodeCredential(); \n",
    "OpenAIClient openAIClientRBAC = new OpenAIClient(new Uri(oAiEndpoint), credentialVSCode);\n",
    "\n",
    "\n",
    "Console.WriteLine($\"OpenAI Client created...\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```\n",
    "Installed Packages\n",
    "    Azure.AI.OpenAI, 1.0.0-beta.12\n",
    "    DotNetEnv, 2.5.0\n",
    "\n",
    "OpenAI Client created...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic interaction with OpenAI Client\n",
    "\n",
    "The following cell, demonstrate a basic interaction with OpenAI Client. In this case, the system message is used to provide instructions or settings for the assistant, such as its personality or behavior. The user message is used to provide queries or inputs from the human user. The assistant message is used to provide responses or outputs from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Azure.Identity.CredentialUnavailableException: Stored credentials not found. Need to authenticate user in VSCode Azure Account.\r\n ---> System.InvalidOperationException: CredRead has failed but error is unknown.\r\n   at Azure.Identity.WindowsNativeMethods.ThrowIfFailed(Boolean isSucceeded, String methodName)\r\n   at Azure.Identity.WindowsNativeMethods.CredRead(String target, CRED_TYPE type)\r\n   at Azure.Identity.WindowsVisualStudioCodeAdapter.GetCredentials(String serviceName, String accountName)\r\n   at Azure.Identity.VisualStudioCodeCredential.GetStoredCredentials(String environmentName)\r\n   --- End of inner exception stack trace ---\r\n   at Azure.Identity.VisualStudioCodeCredential.GetStoredCredentials(String environmentName)\r\n   at Azure.Identity.VisualStudioCodeCredential.GetTokenImplAsync(TokenRequestContext requestContext, Boolean async, CancellationToken cancellationToken)\r\n   at Azure.Identity.CredentialDiagnosticScope.FailWrapAndThrow(Exception ex)\r\n   at Azure.Identity.VisualStudioCodeCredential.GetTokenImplAsync(TokenRequestContext requestContext, Boolean async, CancellationToken cancellationToken)\r\n   at Azure.Identity.VisualStudioCodeCredential.GetTokenAsync(TokenRequestContext requestContext, CancellationToken cancellationToken)\r\n   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AccessTokenCache.GetHeaderValueFromCredentialAsync(TokenRequestContext context, Boolean async, CancellationToken cancellationToken)\r\n   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AccessTokenCache.GetHeaderValueAsync(HttpMessage message, TokenRequestContext context, Boolean async)\r\n   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AccessTokenCache.GetHeaderValueAsync(HttpMessage message, TokenRequestContext context, Boolean async)\r\n   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AuthenticateAndAuthorizeRequestAsync(HttpMessage message, TokenRequestContext context)\r\n   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n   at Azure.Core.Pipeline.RedirectPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n   at Azure.Core.HttpPipelineExtensions.ProcessMessageAsync(HttpPipeline pipeline, HttpMessage message, RequestContext requestContext, CancellationToken cancellationToken)\r\n   at Azure.AI.OpenAI.OpenAIClient.GetChatCompletionsAsync(ChatCompletionsOptions chatCompletionsOptions, CancellationToken cancellationToken)\r\n   at Submission#4.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "Azure.Identity.CredentialUnavailableException: Stored credentials not found. Need to authenticate user in VSCode Azure Account.\r\n",
      " ---> System.InvalidOperationException: CredRead has failed but error is unknown.\r\n",
      "   at Azure.Identity.WindowsNativeMethods.ThrowIfFailed(Boolean isSucceeded, String methodName)\r\n",
      "   at Azure.Identity.WindowsNativeMethods.CredRead(String target, CRED_TYPE type)\r\n",
      "   at Azure.Identity.WindowsVisualStudioCodeAdapter.GetCredentials(String serviceName, String accountName)\r\n",
      "   at Azure.Identity.VisualStudioCodeCredential.GetStoredCredentials(String environmentName)\r\n",
      "   --- End of inner exception stack trace ---\r\n",
      "   at Azure.Identity.VisualStudioCodeCredential.GetStoredCredentials(String environmentName)\r\n",
      "   at Azure.Identity.VisualStudioCodeCredential.GetTokenImplAsync(TokenRequestContext requestContext, Boolean async, CancellationToken cancellationToken)\r\n",
      "   at Azure.Identity.CredentialDiagnosticScope.FailWrapAndThrow(Exception ex)\r\n",
      "   at Azure.Identity.VisualStudioCodeCredential.GetTokenImplAsync(TokenRequestContext requestContext, Boolean async, CancellationToken cancellationToken)\r\n",
      "   at Azure.Identity.VisualStudioCodeCredential.GetTokenAsync(TokenRequestContext requestContext, CancellationToken cancellationToken)\r\n",
      "   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AccessTokenCache.GetHeaderValueFromCredentialAsync(TokenRequestContext context, Boolean async, CancellationToken cancellationToken)\r\n",
      "   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AccessTokenCache.GetHeaderValueAsync(HttpMessage message, TokenRequestContext context, Boolean async)\r\n",
      "   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AccessTokenCache.GetHeaderValueAsync(HttpMessage message, TokenRequestContext context, Boolean async)\r\n",
      "   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.AuthenticateAndAuthorizeRequestAsync(HttpMessage message, TokenRequestContext context)\r\n",
      "   at Azure.Core.Pipeline.BearerTokenAuthenticationPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n",
      "   at Azure.Core.Pipeline.RedirectPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n",
      "   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n",
      "   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\r\n",
      "   at Azure.Core.HttpPipelineExtensions.ProcessMessageAsync(HttpPipeline pipeline, HttpMessage message, RequestContext requestContext, CancellationToken cancellationToken)\r\n",
      "   at Azure.AI.OpenAI.OpenAIClient.GetChatCompletionsAsync(ChatCompletionsOptions chatCompletionsOptions, CancellationToken cancellationToken)\r\n",
      "   at Submission#4.<<Initialize>>d__0.MoveNext()\r\n",
      "--- End of stack trace from previous location ---\r\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "string sys_prompt = \"You are an AI assistance. You extract intention from provided text. You always answer with intention:\";\n",
    "ChatCompletionsOptions simpleOption = new ChatCompletionsOptions();\n",
    "\n",
    "simpleOption.Messages.Add(new ChatRequestSystemMessage(sys_prompt));\n",
    "\n",
    "simpleOption.Messages.Add(new ChatRequestUserMessage( \"I'm not receiving calls on my Samsung Galaxy S22. Can you help?\"));\n",
    "\n",
    "//Request Properties\n",
    "simpleOption.MaxTokens = 500;\n",
    "simpleOption.Temperature = 0.0f;\n",
    "simpleOption.NucleusSamplingFactor = 0.0f;\n",
    "simpleOption.FrequencyPenalty = 0.7f;\n",
    "simpleOption.PresencePenalty = 0.7f;\n",
    "simpleOption.StopSequences.Add(\"\\n\"); \n",
    "simpleOption.DeploymentName = chatCompletionDeploymentName;\n",
    "\n",
    "//Response<ChatCompletions> simpleResponse = await openAIClient.GetChatCompletionsAsync(simpleOption);\n",
    "Response<ChatCompletions> simpleResponse = await openAIClientRBAC.GetChatCompletionsAsync(simpleOption);\n",
    "\n",
    "// Get the first choice from the response\n",
    "ChatCompletions simpleCompletions = simpleResponse.Value;\n",
    "foreach (ChatChoice chatChoice in simpleCompletions.Choices) {\n",
    "    Console.WriteLine($\"ChatChoiceIndex: {chatChoice.Index}\");\n",
    "    Console.WriteLine($\"Content: {chatChoice.Message.Content}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "ChatChoiceIndex: 0\n",
    "Content: Intention: Request for technical assistance with phone call issue on Samsung Galaxy S22.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compose Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Define System Prompt\n",
    "string systemPrompt = @\" \n",
    "    You extract intention from provided text. The two intentions you identify are: product information and order status. \n",
    "    You answer with a valid JSON string. \n",
    "    The JSON string must have the format {\"\"Intention\"\": \"\"ProductInformation\"\"} or {\"\"Intention\"\": \"\"OrderInfo\"\"}. \n",
    "    You don't provide additional information. \n",
    "    If you can't identify intention answer with {\"\"Intention\"\": \"\"Unknown\"\"}\n",
    "\";\n",
    "\n",
    "// Compose Chat (Few Shot Learning)\n",
    "ChatCompletionsOptions chatCompletionsOptions = new ChatCompletionsOptions();\n",
    "\n",
    "// Add messages using the new methods\n",
    "chatCompletionsOptions.Messages.Add(new ChatRequestSystemMessage(systemPrompt));\n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatRequestUserMessage(\"I've purchased three weeks ago new training shoes. When will they will be delivered?\"));\n",
    "// Assuming that the assistant responses are generated by the AI and not predefined, we don't add them here\n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatRequestUserMessage(\"Still waiting for the delivery. Any idea when it will arrive? I'm Robert and I'm calling on behalf of company Contoso.\"));\n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatRequestUserMessage(\"Do you have training shoes? If yes, I'm interested in running equipment specifically running shoes.\"));\n",
    "\n",
    "chatCompletionsOptions.Messages.Add(new ChatRequestUserMessage(\"What is the average price for running shoes?\"));\n",
    "\n",
    "// Request Properties\n",
    "chatCompletionsOptions.MaxTokens = 500;\n",
    "chatCompletionsOptions.Temperature = 0.0f;\n",
    "chatCompletionsOptions.NucleusSamplingFactor = 0.0f;\n",
    "chatCompletionsOptions.FrequencyPenalty = 0.7f;\n",
    "chatCompletionsOptions.PresencePenalty = 0.7f;\n",
    "chatCompletionsOptions.StopSequences.Add(\"\\n\"); \n",
    "\n",
    "// Deployment Name\n",
    "chatCompletionsOptions.DeploymentName = chatCompletionDeploymentName;\n",
    "\n",
    "Console.WriteLine(\"ChatCompletionsOptions created...\");\n",
    "\n",
    "// Get Chat Completions\n",
    "Response<ChatCompletions> response = await openAIClient.GetChatCompletionsAsync(chatCompletionsOptions);\n",
    "\n",
    "// Handle the response\n",
    "ChatCompletions chatCompletions = response.Value;\n",
    "foreach (ChatChoice chatChoice in chatCompletions.Choices) {\n",
    "    Console.WriteLine($\"ChatChoiceIndex: {chatChoice.Index}\");\n",
    "    Console.WriteLine($\"Content: {chatChoice.Message.Content}\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "ChatCompletionsOptions created...\n",
    "ChatChoiceIndex: 0\n",
    "Content: {\"Intention\": \"ProductInformation\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Call OpenAI ChatCompletion Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Add user input to the chat completions options using the new method\n",
    "chatCompletionsOptions.Messages.Add(new ChatRequestUserMessage(\"How much do you charge for a pair of first-class running shoes?\"));\n",
    "\n",
    "// Call the Model ChatCompletions endpoint\n",
    "// Note: The updated method no longer takes the deployment name as a separate parameter\n",
    "Response<ChatCompletions> response = await openAIClient.GetChatCompletionsAsync(chatCompletionsOptions);\n",
    "\n",
    "// Get the first choice from the response\n",
    "ChatCompletions chatCompletions = response.Value;\n",
    "foreach (ChatChoice chatChoice in chatCompletions.Choices) {\n",
    "    Console.WriteLine($\"ChatChoiceIndex: {chatChoice.Index}\");\n",
    "    Console.WriteLine($\"Content: {chatChoice.Message.Content}\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "ChatChoiceIndex: 0\n",
    "Content: {\"Intention\": \"ProductInfo\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check additional response values\n",
    "\n",
    "### Token Usage\n",
    "\n",
    "Tokens consumed by the `GetChatCompletionsAsync()` call can be retrieved by parsing the raw response from the call as the `\"nuget: Azure.AI.OpenAI, 1.0.0-beta.7\"` does not provide the information as property yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//Get Raw Response\n",
    "var rawResponse = response.GetRawResponse();\n",
    "if (!rawResponse.IsError) {\n",
    "    //Get Raw Response Content\n",
    "    JsonElement jsonElement = JsonSerializer.Deserialize<JsonElement>(rawResponse.Content.ToString());\n",
    "    JsonElement tokenUsage = jsonElement.GetProperty(\"usage\");\n",
    "    tokenUsage.TryGetProperty(\"completion_tokens\", out JsonElement completionTokens);\n",
    "    Console.WriteLine($\"Completion Tokens: {completionTokens.ToString()}\");\n",
    "    tokenUsage.TryGetProperty(\"prompt_tokens\", out JsonElement promptTokens);\n",
    "    Console.WriteLine($\"Prompt Tokens: {promptTokens.ToString()}\");\n",
    "    tokenUsage.TryGetProperty(\"total_tokens\", out JsonElement totalTokens);\n",
    "    Console.WriteLine($\"Total Tokens: {totalTokens.ToString()}\");\n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected outcome:\n",
    "\n",
    "```\n",
    "Completion Tokens: <value>\n",
    "Prompt Tokens: <value>\n",
    "Total Tokens: <value>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter \n",
    "\n",
    "If the LLM detects:\n",
    "- hate\n",
    "- self harm\n",
    "- violence\n",
    "- sexual\n",
    "content within the provided prompt or in the result it will be filtered and reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//Prompt Filter\n",
    "Console.WriteLine($\"Prompt Filter Results\");\n",
    "foreach(ContentFilterResultsForPrompt promptFilterResult in chatCompletions.PromptFilterResults) {\n",
    "    Console.WriteLine($\"PromptIndex: {promptFilterResult.PromptIndex}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Hate\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.Hate.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.Hate.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: SelfHarm\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.SelfHarm.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.SelfHarm.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Violence\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.Violence.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.Violence.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Sexual\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {promptFilterResult.ContentFilterResults.Sexual.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {promptFilterResult.ContentFilterResults.Sexual.Severity}\");\n",
    "}\n",
    "\n",
    "//Response Filter\n",
    "foreach (ChatChoice chatChoice in chatCompletions.Choices) {\n",
    "    Console.WriteLine($\"ChatChoiceIndex: {chatChoice.Index}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Hate\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.Hate.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.Hate.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: SelfHarm\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.SelfHarm.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.SelfHarm.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Violence\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.Violence.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.Violence.Severity}\");\n",
    "    Console.WriteLine($\"\\t ContentFilterResults: Sexual\");\n",
    "    Console.WriteLine($\"\\t\\t Filtered: {chatChoice.ContentFilterResults.Sexual.Filtered}\");\n",
    "    Console.WriteLine($\"\\t\\t Severity: {chatChoice.ContentFilterResults.Sexual.Severity}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output\n",
    "\n",
    "```\n",
    "Prompt Filter Results\n",
    "ChatChoiceIndex: 0\n",
    "\t ContentFilterResults: Hate\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: SelfHarm\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Violence\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Sexual\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "ChatChoiceIndex: 1\n",
    "\t ContentFilterResults: Hate\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: SelfHarm\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Violence\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "\t ContentFilterResults: Sexual\n",
    "\t\t Filtered: False\n",
    "\t\t Severity: safe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- The result from the result was received as a single object. Streaming is useful in scenario where the response is large, and the client wants to process the response as it is received. [Demo Streaming](./02_ChatCompletionStreaming.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
